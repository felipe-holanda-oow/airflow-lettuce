[core]
broker_url = $REDIS_URL
sql_alchemy_conn = $DATABASE_URL
executor = CeleryExecutor
load_examples = True

[webserver]
authenticate = True
auth_backend = airflow.contrib.auth.backends.password_auth
rbac = True

[database]
sql_alchemy_conn = $DATABASE_URL

[celery]
broker_url = $REDIS_URL
result_backend = $REDIS_URL
worker_concurrency = 2


[logging]
# Airflow can store logs remotely in AWS S3. Users must supply a remote
# location URL (starting with either 's3://...') and an Airflow connection
# id that provides access to the storage location.
remote_logging = True
remote_base_log_folder = s3://lettucegrow-airflow-etl/logs
remote_log_conn_id = my_conn_s3
# Use server-side encryption for logs stored in S3
encrypt_s3_logs = False